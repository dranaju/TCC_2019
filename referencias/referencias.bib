@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{tai2017virtual,
  title={Virtual-to-real deep reinforcement learning: Continuous control of mobile robots for mapless navigation},
  author={Tai, Lei and Paolo, Giuseppe and Liu, Ming},
  booktitle={Intelligent Robots and Systems (IROS), 2017 IEEE/RSJ International Conference on},
  pages={31--36},
  year={2017},
  organization={IEEE}
}

@inproceedings{zhu2017target,
  title={Target-driven visual navigation in indoor scenes using deep reinforcement learning},
  author={Zhu, Yuke and Mottaghi, Roozbeh and Kolve, Eric and Lim, Joseph J and Gupta, Abhinav and Fei-Fei, Li and Farhadi, Ali},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={3357--3364},
  year={2017},
  organization={IEEE}
}

@article{tai2016towards,
  title={Towards cognitive exploration through deep reinforcement learning for mobile robots},
  author={Tai, Lei and Liu, Ming},
  journal={arXiv preprint arXiv:1610.01733},
  year={2016}
}

@inproceedings{chen2017socially,
  title={Socially aware motion planning with deep reinforcement learning},
  author={Chen, Yu Fan and Everett, Michael and Liu, Miao and How, Jonathan P},
  booktitle={Intelligent Robots and Systems (IROS), 2017 IEEE/RSJ International Conference on},
  pages={1343--1350},
  year={2017},
  organization={IEEE}
}

@book{fairchild2016ros,
  title={ROS Robotics By Example},
  author={Fairchild, Carol and Harman, Thomas L},
  year={2016},
  publisher={Packt Publishing Ltd}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@book{ascher1999learning,
  title={Learning Python},
  author={Ascher, David and Lutz, Mark},
  year={1999},
  publisher={O'Reilly}
}

@article{pyo2015ros,
  title={ROS robot programming},
  author={Pyo, YoonSeok and Cho, HanCheol and Jung, RyuWoon and Lim, TaeHoon},
  journal={Seoul, ROBOTIS Co},
  year={2015}
}

@inproceedings{gu2016continuous,
  title={Continuous deep q-learning with model-based acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={2829--2838},
  year={2016}
}

@article{uhlenbeck1930theory,
  title={On the theory of the Brownian motion},
  author={Uhlenbeck, George E and Ornstein, Leonard S},
  journal={Physical review},
  volume={36},
  number={5},
  pages={823},
  year={1930},
  publisher={APS}
}

@inproceedings{hausknecht2015deep,
  title={Deep recurrent q-learning for partially observable mdps},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={2015 AAAI Fall Symposium Series},
  year={2015}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@book{joseph2015mastering,
  title={Mastering ROS for robotics programming},
  author={Joseph, Lentin},
  year={2015},
  publisher={Packt Publishing Ltd}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{nachum2017trust,
  title={Trust-pcl: An off-policy trust region method for continuous control},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1707.01891},
  year={2017}
}

@article{kalashnikov2018qt,
  title={Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  journal={arXiv preprint arXiv:1806.10293},
  year={2018}
}

@article{mahmood2018benchmarking,
  title={Benchmarking reinforcement learning algorithms on real-world robots},
  author={Mahmood, A Rupam and Korenkevych, Dmytro and Vasan, Gautham and Ma, William and Bergstra, James},
  journal={arXiv preprint arXiv:1809.07731},
  year={2018}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{arulkumaran2017brief,
  title={A brief survey of deep reinforcement learning},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={arXiv preprint arXiv:1708.05866},
  year={2017}
}

@article{li2017deep,
  title={Deep reinforcement learning: An overview},
  author={Li, Yuxi},
  journal={arXiv preprint arXiv:1701.07274},
  year={2017}
}

@inproceedings{luo2005artificial,
  title={Artificial neural network computation on graphic process unit},
  author={Luo, Zhongwen and Liu, Hongzhi and Wu, Xincai},
  booktitle={Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.},
  volume={1},
  pages={622--626},
  year={2005},
  organization={IEEE}
}

@inproceedings{asano2009performance,
  title={Performance comparison of FPGA, GPU and CPU in image processing},
  author={Asano, Shuichi and Maruyama, Tsutomu and Yamaguchi, Yoshiki},
  booktitle={2009 international conference on field programmable logic and applications},
  pages={126--131},
  year={2009},
  organization={IEEE}
}

@article{shabbir2018survey,
  title={A survey of deep learning techniques for mobile robot applications},
  author={Shabbir, Jahanzaib and Anwer, Tarique},
  journal={arXiv preprint arXiv:1803.07608},
  year={2018}
}

@article{stone2005reinforcement,
  title={Reinforcement learning for robocup soccer keepaway},
  author={Stone, Peter and Sutton, Richard S and Kuhlmann, Gregory},
  journal={Adaptive Behavior},
  volume={13},
  number={3},
  pages={165--188},
  year={2005},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{mitchell1990machine,
  title={Machine learning},
  author={Mitchell, Tom and Buchanan, Bruce and DeJong, Gerald and Dietterich, Thomas and Rosenbloom, Paul and Waibel, Alex},
  journal={Annual review of computer science},
  volume={4},
  number={1},
  pages={417--433},
  year={1990},
  publisher={Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA}
}

@article{franccois2018introduction,
  title={An introduction to deep reinforcement learning},
  author={Fran{\c{c}}ois-Lavet, Vincent and Henderson, Peter and Islam, Riashat and Bellemare, Marc G and Pineau, Joelle and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={3-4},
  pages={219--354},
  year={2018},
  publisher={Now Publishers, Inc.}
}

@book{sutton1998introduction,
  title={Introduction to reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={135},
  year={1998},
  publisher={MIT press Cambridge}
}

@book{bellman2015applied,
  title={Applied dynamic programming},
  author={Bellman, Richard E and Dreyfus, Stuart E},
  volume={2050},
  year={2015},
  publisher={Princeton university press}
}

@article{bellman1957markovian,
  title={A Markovian decision process},
  author={Bellman, Richard},
  journal={Journal of Mathematics and Mechanics},
  pages={679--684},
  year={1957},
  publisher={JSTOR}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@book{forsyth2002computer,
  title={Computer vision: a modern approach},
  author={Forsyth, David A and Ponce, Jean},
  year={2002},
  publisher={Prentice Hall Professional Technical Reference}
}

@article{ballard1982computer,
  title={Computer vision. englewood cliffs},
  author={Ballard, Dana H and Brown, Christopher M},
  journal={J: Prentice Hall},
  year={1982}
}

@inproceedings{bascle1995region,
  title={Region tracking through image sequences},
  author={Bascle, Benedicte and Deriche, Rachid},
  booktitle={Proceedings of IEEE International Conference on Computer Vision},
  pages={302--307},
  year={1995},
  organization={IEEE}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@misc{robotisemanual,
    author    = {ROBOTIS},
    title     = "ROBOTIS e-Manual Turtlebot3",
    howpublished = "https://github.com/ROBOTIS-GIT/emanual/tree/master/docs/en/platform/turtlebot3",
    year     = "2019",
    note     = "Acessado em Julho 2019",
}

@book{bradski2008learning,
  title={Learning OpenCV: Computer vision with the OpenCV library},
  author={Bradski, Gary and Kaehler, Adrian},
  year={2008},
  publisher={" O'Reilly Media, Inc."}
}

@inproceedings{oyama2009come,
  title={Come on in, our community is wide open for robotics research},
  author={Oyama, Akihisa and Konolige, K and Cousins, S and Chitta, S and Conley, K and Bradski, G},
  booktitle={The 27th annual conference of the robotics society of Japan},
  volume={9},
  pages={2009},
  year={2009}
}

@inproceedings{wang2010camera,
  title={A camera calibration technique based on OpenCV},
  author={Wang, YM and Li, Y and Zheng, JB},
  booktitle={The 3rd International Conference on Information Sciences and Interaction Sciences},
  pages={403--406},
  year={2010},
  organization={IEEE}
}